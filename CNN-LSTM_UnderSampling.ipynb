{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## CNN-LSTM IoMT IDS\n",
    "### CSCI 6505 Group Project\n",
    "### Author: Hongwei Zhang & Koil Jat Chong\n",
    "### Enhancing Intrusion Detection in Healthcare IoMT Devices Using the CNN-LSTM Model"
   ],
   "id": "8f9f2b260b00d34"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T19:03:50.413920Z",
     "start_time": "2024-12-01T19:03:50.406236Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import sys\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"Version info:\", sys.version_info)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]\n",
      "Version info: sys.version_info(major=3, minor=10, micro=11, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T19:03:50.666716Z",
     "start_time": "2024-12-01T19:03:50.428105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('./dataset/processed_data.csv')\n",
    "data.head()"
   ],
   "id": "8172e0c3ed0c6b85",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Header_Length  Protocol Type  Duration      Rate     Srate  Drate  \\\n",
       "0       0.012399       0.482353  0.301176  0.000009  0.000009    0.0   \n",
       "1       0.005670       0.417647  0.217647  0.000003  0.000003    0.0   \n",
       "2       0.269644       1.000000  0.250980  0.000021  0.000021    0.0   \n",
       "3       0.806794       1.000000  0.250980  0.000192  0.000192    0.0   \n",
       "4       0.000011       0.352941  0.184314  0.000010  0.000010    0.0   \n",
       "\n",
       "   fin_flag_number  syn_flag_number  rst_flag_number  psh_flag_number  ...  \\\n",
       "0              0.0              0.0              0.0              0.5  ...   \n",
       "1              0.0              0.1              0.0              0.5  ...   \n",
       "2              0.0              0.0              0.0              0.0  ...   \n",
       "3              0.0              0.0              0.0              0.0  ...   \n",
       "4              0.0              1.0              0.0              0.0  ...   \n",
       "\n",
       "        Std  Tot size           IAT    Number  Magnitue    Radius  Covariance  \\\n",
       "0  0.465433  0.041508  9.999574e-01  0.925926  0.217273  0.466105    0.218837   \n",
       "1  0.223835  0.073505  3.288045e-10  0.333333  0.181740  0.223663    0.066195   \n",
       "2  0.187570  0.239402  3.395595e-11  0.333333  0.249725  0.187426    0.068553   \n",
       "3  0.643992  0.305027  9.996046e-01  0.925926  0.438889  0.644289    0.415955   \n",
       "4  0.148112  0.010870  9.996509e-01  0.925926  0.085875  0.148318    0.022161   \n",
       "\n",
       "   Variance    Weight  Target  \n",
       "0       1.0  1.000000       0  \n",
       "1       0.9  0.153941       4  \n",
       "2       0.9  0.153941       4  \n",
       "3       1.0  1.000000       5  \n",
       "4       1.0  1.000000       4  \n",
       "\n",
       "[5 rows x 46 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header_Length</th>\n",
       "      <th>Protocol Type</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Srate</th>\n",
       "      <th>Drate</th>\n",
       "      <th>fin_flag_number</th>\n",
       "      <th>syn_flag_number</th>\n",
       "      <th>rst_flag_number</th>\n",
       "      <th>psh_flag_number</th>\n",
       "      <th>...</th>\n",
       "      <th>Std</th>\n",
       "      <th>Tot size</th>\n",
       "      <th>IAT</th>\n",
       "      <th>Number</th>\n",
       "      <th>Magnitue</th>\n",
       "      <th>Radius</th>\n",
       "      <th>Covariance</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012399</td>\n",
       "      <td>0.482353</td>\n",
       "      <td>0.301176</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465433</td>\n",
       "      <td>0.041508</td>\n",
       "      <td>9.999574e-01</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.217273</td>\n",
       "      <td>0.466105</td>\n",
       "      <td>0.218837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005670</td>\n",
       "      <td>0.417647</td>\n",
       "      <td>0.217647</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223835</td>\n",
       "      <td>0.073505</td>\n",
       "      <td>3.288045e-10</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.181740</td>\n",
       "      <td>0.223663</td>\n",
       "      <td>0.066195</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.153941</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.269644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187570</td>\n",
       "      <td>0.239402</td>\n",
       "      <td>3.395595e-11</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.249725</td>\n",
       "      <td>0.187426</td>\n",
       "      <td>0.068553</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.153941</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.806794</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643992</td>\n",
       "      <td>0.305027</td>\n",
       "      <td>9.996046e-01</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.438889</td>\n",
       "      <td>0.644289</td>\n",
       "      <td>0.415955</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.184314</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148112</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>9.996509e-01</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.085875</td>\n",
       "      <td>0.148318</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T19:03:50.746337Z",
     "start_time": "2024-12-01T19:03:50.731280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract features and labels\n",
    "X = data.drop(columns=['Target']).values\n",
    "y = data['Target'].values\n",
    "print(f'X: {X.shape}, y: {y.shape}')"
   ],
   "id": "d4f13bb62e5582c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (96282, 45), y: (96282,)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T19:03:50.872550Z",
     "start_time": "2024-12-01T19:03:50.826557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "# 70% training, 15% validation, 15% testing\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.5, random_state=42)\n",
    "print('Train set:', X_train.shape, y_train.shape)\n",
    "print('Validation set:', X_val.shape, y_val.shape)\n",
    "print('Test set:', X_test.shape, y_test.shape)"
   ],
   "id": "972865da6c7b449b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (67397, 45) (67397,)\n",
      "Validation set: (14442, 45) (14442,)\n",
      "Test set: (14443, 45) (14443,)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T19:03:50.982228Z",
     "start_time": "2024-12-01T19:03:50.967181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.int64)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), \n",
    "                          batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=batch_size)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size)"
   ],
   "id": "ffa906fdf448af86",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T19:03:51.029747Z",
     "start_time": "2024-12-01T19:03:51.015728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the model\n",
    "class CNN_LSTM_Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(CNN_LSTM_Model, self).__init__()\n",
    "        \n",
    "        # CNN layer for extracting spatial features\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_size, out_channels=16, \n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, \n",
    "                      kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # LSTM layer for extracting temporal features\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=32, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(2)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out = self.cnn(x)\n",
    "        out = out.permute(0, 2, 1)\n",
    "        out, _ = self.lstm(out)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ],
   "id": "3d119beb40fb88f3",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T19:03:51.045746Z",
     "start_time": "2024-12-01T19:03:51.033727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "input_size = 1\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "num_classes = 6\n",
    "\n",
    "model = CNN_LSTM_Model(input_size, hidden_size, num_layers, num_classes)\n",
    "print(model.to('cpu'))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "9fa02a598f044d82",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_LSTM_Model(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (lstm): LSTM(32, 50, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=50, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T19:03:51.123874Z",
     "start_time": "2024-12-01T19:03:51.109875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training function\n",
    "def train(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "    return running_loss / len(dataloader.dataset)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Compute additional metrics\n",
    "    accuracy = correct / len(dataloader.dataset)\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    return running_loss / len(dataloader.dataset), accuracy, precision, recall, f1"
   ],
   "id": "6aac44cf614bc57d",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T21:09:00.955682Z",
     "start_time": "2024-12-01T19:04:51.846752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train and evaluate the model\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc, val_prec, val_rec, val_f1 = evaluate(model, val_loader, criterion)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: <Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}, Val Acc: {val_acc:.6f}, Val Prec: {val_prec:.6f}, Val Rec: {val_rec:.6f}, Val F1: {val_f1:.6f}>\")"
   ],
   "id": "e9768473b6539749",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: <Train Loss: 0.406522, Val Loss: 0.391232, Val Acc: 0.806190, Val Prec: 0.815095, Val Rec: 0.804877, Val F1: 0.805641>\n",
      "Epoch 2/100: <Train Loss: 0.394176, Val Loss: 0.401316, Val Acc: 0.780086, Val Prec: 0.790741, Val Rec: 0.780929, Val F1: 0.770149>\n",
      "Epoch 3/100: <Train Loss: 0.385593, Val Loss: 0.379713, Val Acc: 0.817546, Val Prec: 0.822824, Val Rec: 0.816464, Val F1: 0.816167>\n",
      "Epoch 4/100: <Train Loss: 0.379270, Val Loss: 0.379896, Val Acc: 0.800235, Val Prec: 0.812737, Val Rec: 0.800034, Val F1: 0.796756>\n",
      "Epoch 5/100: <Train Loss: 0.374695, Val Loss: 0.361628, Val Acc: 0.821216, Val Prec: 0.830351, Val Rec: 0.819827, Val F1: 0.818068>\n",
      "Epoch 6/100: <Train Loss: 0.368926, Val Loss: 0.362413, Val Acc: 0.819277, Val Prec: 0.828797, Val Rec: 0.817953, Val F1: 0.818542>\n",
      "Epoch 7/100: <Train Loss: 0.364931, Val Loss: 0.360364, Val Acc: 0.808891, Val Prec: 0.819990, Val Rec: 0.809175, Val F1: 0.803314>\n",
      "Epoch 8/100: <Train Loss: 0.362044, Val Loss: 0.355060, Val Acc: 0.821839, Val Prec: 0.827910, Val Rec: 0.820718, Val F1: 0.820202>\n",
      "Epoch 9/100: <Train Loss: 0.359487, Val Loss: 0.355028, Val Acc: 0.823224, Val Prec: 0.830497, Val Rec: 0.822054, Val F1: 0.822263>\n",
      "Epoch 10/100: <Train Loss: 0.356697, Val Loss: 0.355118, Val Acc: 0.823847, Val Prec: 0.831544, Val Rec: 0.822618, Val F1: 0.822719>\n",
      "Epoch 11/100: <Train Loss: 0.354307, Val Loss: 0.350404, Val Acc: 0.824263, Val Prec: 0.831534, Val Rec: 0.823040, Val F1: 0.821693>\n",
      "Epoch 12/100: <Train Loss: 0.350986, Val Loss: 0.349601, Val Acc: 0.822324, Val Prec: 0.829691, Val Rec: 0.821086, Val F1: 0.819405>\n",
      "Epoch 13/100: <Train Loss: 0.348279, Val Loss: 0.348390, Val Acc: 0.803836, Val Prec: 0.843977, Val Rec: 0.804852, Val F1: 0.778444>\n",
      "Epoch 14/100: <Train Loss: 0.346752, Val Loss: 0.343018, Val Acc: 0.827517, Val Prec: 0.834280, Val Rec: 0.826413, Val F1: 0.826931>\n",
      "Epoch 15/100: <Train Loss: 0.344402, Val Loss: 0.343173, Val Acc: 0.828625, Val Prec: 0.833560, Val Rec: 0.827683, Val F1: 0.827934>\n",
      "Epoch 16/100: <Train Loss: 0.342263, Val Loss: 0.351190, Val Acc: 0.809860, Val Prec: 0.817905, Val Rec: 0.810400, Val F1: 0.805442>\n",
      "Epoch 17/100: <Train Loss: 0.340742, Val Loss: 0.342735, Val Acc: 0.829594, Val Prec: 0.837397, Val Rec: 0.828405, Val F1: 0.828833>\n",
      "Epoch 18/100: <Train Loss: 0.338844, Val Loss: 0.344657, Val Acc: 0.827171, Val Prec: 0.830890, Val Rec: 0.826367, Val F1: 0.826334>\n",
      "Epoch 19/100: <Train Loss: 0.337938, Val Loss: 0.343537, Val Acc: 0.824817, Val Prec: 0.833465, Val Rec: 0.823453, Val F1: 0.822134>\n",
      "Epoch 20/100: <Train Loss: 0.335959, Val Loss: 0.338574, Val Acc: 0.821631, Val Prec: 0.828897, Val Rec: 0.821375, Val F1: 0.820533>\n",
      "Epoch 21/100: <Train Loss: 0.334085, Val Loss: 0.342269, Val Acc: 0.828348, Val Prec: 0.834369, Val Rec: 0.827340, Val F1: 0.827979>\n",
      "Epoch 22/100: <Train Loss: 0.333457, Val Loss: 0.338464, Val Acc: 0.831533, Val Prec: 0.834700, Val Rec: 0.830773, Val F1: 0.830666>\n",
      "Epoch 23/100: <Train Loss: 0.332564, Val Loss: 0.339066, Val Acc: 0.831325, Val Prec: 0.836694, Val Rec: 0.830326, Val F1: 0.830383>\n",
      "Epoch 24/100: <Train Loss: 0.331097, Val Loss: 0.337562, Val Acc: 0.831533, Val Prec: 0.838294, Val Rec: 0.830422, Val F1: 0.830748>\n",
      "Epoch 25/100: <Train Loss: 0.330513, Val Loss: 0.336450, Val Acc: 0.830010, Val Prec: 0.840081, Val Rec: 0.828591, Val F1: 0.827094>\n",
      "Epoch 26/100: <Train Loss: 0.327616, Val Loss: 0.335840, Val Acc: 0.832364, Val Prec: 0.835686, Val Rec: 0.831611, Val F1: 0.831536>\n",
      "Epoch 27/100: <Train Loss: 0.326163, Val Loss: 0.333342, Val Acc: 0.832018, Val Prec: 0.838211, Val Rec: 0.830901, Val F1: 0.830951>\n",
      "Epoch 28/100: <Train Loss: 0.325517, Val Loss: 0.337275, Val Acc: 0.832918, Val Prec: 0.837567, Val Rec: 0.832015, Val F1: 0.832248>\n",
      "Epoch 29/100: <Train Loss: 0.323689, Val Loss: 0.349706, Val Acc: 0.809029, Val Prec: 0.811171, Val Rec: 0.808799, Val F1: 0.809341>\n",
      "Epoch 30/100: <Train Loss: 0.324784, Val Loss: 0.332180, Val Acc: 0.833749, Val Prec: 0.840594, Val Rec: 0.832605, Val F1: 0.832532>\n",
      "Epoch 31/100: <Train Loss: 0.322434, Val Loss: 0.328216, Val Acc: 0.839080, Val Prec: 0.844757, Val Rec: 0.838164, Val F1: 0.839122>\n",
      "Epoch 32/100: <Train Loss: 0.321784, Val Loss: 0.330501, Val Acc: 0.832710, Val Prec: 0.838175, Val Rec: 0.831659, Val F1: 0.831656>\n",
      "Epoch 33/100: <Train Loss: 0.319576, Val Loss: 0.329714, Val Acc: 0.834718, Val Prec: 0.838247, Val Rec: 0.833945, Val F1: 0.834405>\n",
      "Epoch 34/100: <Train Loss: 0.317888, Val Loss: 0.330232, Val Acc: 0.839427, Val Prec: 0.846069, Val Rec: 0.838313, Val F1: 0.838552>\n",
      "Epoch 35/100: <Train Loss: 0.316202, Val Loss: 0.333378, Val Acc: 0.831602, Val Prec: 0.834337, Val Rec: 0.830985, Val F1: 0.831599>\n",
      "Epoch 36/100: <Train Loss: 0.312046, Val Loss: 0.326489, Val Acc: 0.842750, Val Prec: 0.845105, Val Rec: 0.842179, Val F1: 0.842741>\n",
      "Epoch 37/100: <Train Loss: 0.310590, Val Loss: 0.340597, Val Acc: 0.819693, Val Prec: 0.829171, Val Rec: 0.819968, Val F1: 0.815612>\n",
      "Epoch 38/100: <Train Loss: 0.313322, Val Loss: 0.348313, Val Acc: 0.809583, Val Prec: 0.813993, Val Rec: 0.809253, Val F1: 0.809528>\n",
      "Epoch 39/100: <Train Loss: 0.308218, Val Loss: 0.326213, Val Acc: 0.845382, Val Prec: 0.848004, Val Rec: 0.844857, Val F1: 0.845662>\n",
      "Epoch 40/100: <Train Loss: 0.305229, Val Loss: 0.324952, Val Acc: 0.847251, Val Prec: 0.850384, Val Rec: 0.846685, Val F1: 0.847577>\n",
      "Epoch 41/100: <Train Loss: 0.305697, Val Loss: 0.336934, Val Acc: 0.835480, Val Prec: 0.838367, Val Rec: 0.834723, Val F1: 0.834947>\n",
      "Epoch 42/100: <Train Loss: 0.306123, Val Loss: 0.328736, Val Acc: 0.841919, Val Prec: 0.846096, Val Rec: 0.841592, Val F1: 0.841919>\n",
      "Epoch 43/100: <Train Loss: 0.303785, Val Loss: 0.324327, Val Acc: 0.849259, Val Prec: 0.852398, Val Rec: 0.848925, Val F1: 0.849472>\n",
      "Epoch 44/100: <Train Loss: 0.301075, Val Loss: 0.326411, Val Acc: 0.847459, Val Prec: 0.849556, Val Rec: 0.847079, Val F1: 0.847711>\n",
      "Epoch 45/100: <Train Loss: 0.301108, Val Loss: 0.325359, Val Acc: 0.848705, Val Prec: 0.851303, Val Rec: 0.848356, Val F1: 0.849056>\n",
      "Epoch 46/100: <Train Loss: 0.301763, Val Loss: 0.330865, Val Acc: 0.843443, Val Prec: 0.847022, Val Rec: 0.843099, Val F1: 0.843599>\n",
      "Epoch 47/100: <Train Loss: 0.301296, Val Loss: 0.327490, Val Acc: 0.846212, Val Prec: 0.849957, Val Rec: 0.845809, Val F1: 0.846466>\n",
      "Epoch 48/100: <Train Loss: 0.299882, Val Loss: 0.326505, Val Acc: 0.845312, Val Prec: 0.848856, Val Rec: 0.844596, Val F1: 0.845407>\n",
      "Epoch 49/100: <Train Loss: 0.296844, Val Loss: 0.328645, Val Acc: 0.846074, Val Prec: 0.850032, Val Rec: 0.845267, Val F1: 0.845977>\n",
      "Epoch 50/100: <Train Loss: 0.296155, Val Loss: 0.337245, Val Acc: 0.837626, Val Prec: 0.840915, Val Rec: 0.836912, Val F1: 0.836466>\n",
      "Epoch 51/100: <Train Loss: 0.295801, Val Loss: 0.325186, Val Acc: 0.850298, Val Prec: 0.852629, Val Rec: 0.849925, Val F1: 0.850574>\n",
      "Epoch 52/100: <Train Loss: 0.294571, Val Loss: 0.327530, Val Acc: 0.849675, Val Prec: 0.851995, Val Rec: 0.849350, Val F1: 0.850009>\n",
      "Epoch 53/100: <Train Loss: 0.293820, Val Loss: 0.325904, Val Acc: 0.848428, Val Prec: 0.849910, Val Rec: 0.848150, Val F1: 0.848638>\n",
      "Epoch 54/100: <Train Loss: 0.293248, Val Loss: 0.331657, Val Acc: 0.846697, Val Prec: 0.850037, Val Rec: 0.846063, Val F1: 0.846946>\n",
      "Epoch 55/100: <Train Loss: 0.291366, Val Loss: 0.330189, Val Acc: 0.848705, Val Prec: 0.851064, Val Rec: 0.848248, Val F1: 0.848975>\n",
      "Epoch 56/100: <Train Loss: 0.291443, Val Loss: 0.325630, Val Acc: 0.848290, Val Prec: 0.852079, Val Rec: 0.847714, Val F1: 0.848612>\n",
      "Epoch 57/100: <Train Loss: 0.289919, Val Loss: 0.355192, Val Acc: 0.829594, Val Prec: 0.835483, Val Rec: 0.829440, Val F1: 0.828635>\n",
      "Epoch 58/100: <Train Loss: 0.290829, Val Loss: 0.336365, Val Acc: 0.840188, Val Prec: 0.844462, Val Rec: 0.840109, Val F1: 0.839558>\n",
      "Epoch 59/100: <Train Loss: 0.288590, Val Loss: 0.328090, Val Acc: 0.848428, Val Prec: 0.850096, Val Rec: 0.848174, Val F1: 0.848674>\n",
      "Epoch 60/100: <Train Loss: 0.288791, Val Loss: 0.328115, Val Acc: 0.850021, Val Prec: 0.853116, Val Rec: 0.849503, Val F1: 0.850344>\n",
      "Epoch 61/100: <Train Loss: 0.287843, Val Loss: 0.334463, Val Acc: 0.845866, Val Prec: 0.848984, Val Rec: 0.845619, Val F1: 0.845902>\n",
      "Epoch 62/100: <Train Loss: 0.288285, Val Loss: 0.339558, Val Acc: 0.840742, Val Prec: 0.844385, Val Rec: 0.840530, Val F1: 0.840504>\n",
      "Epoch 63/100: <Train Loss: 0.287346, Val Loss: 0.332102, Val Acc: 0.848013, Val Prec: 0.849977, Val Rec: 0.847435, Val F1: 0.847873>\n",
      "Epoch 64/100: <Train Loss: 0.284810, Val Loss: 0.328004, Val Acc: 0.848497, Val Prec: 0.851978, Val Rec: 0.847892, Val F1: 0.848738>\n",
      "Epoch 65/100: <Train Loss: 0.285658, Val Loss: 0.334101, Val Acc: 0.848982, Val Prec: 0.851747, Val Rec: 0.848640, Val F1: 0.849151>\n",
      "Epoch 66/100: <Train Loss: 0.283935, Val Loss: 0.328223, Val Acc: 0.850782, Val Prec: 0.852682, Val Rec: 0.850430, Val F1: 0.850926>\n",
      "Epoch 67/100: <Train Loss: 0.284839, Val Loss: 0.335009, Val Acc: 0.848220, Val Prec: 0.850694, Val Rec: 0.847676, Val F1: 0.848441>\n",
      "Epoch 68/100: <Train Loss: 0.282660, Val Loss: 0.344741, Val Acc: 0.842335, Val Prec: 0.845929, Val Rec: 0.842053, Val F1: 0.842496>\n",
      "Epoch 69/100: <Train Loss: 0.283652, Val Loss: 0.336667, Val Acc: 0.851267, Val Prec: 0.854459, Val Rec: 0.850628, Val F1: 0.851457>\n",
      "Epoch 70/100: <Train Loss: 0.282554, Val Loss: 0.345024, Val Acc: 0.836657, Val Prec: 0.854202, Val Rec: 0.837245, Val F1: 0.830008>\n",
      "Epoch 71/100: <Train Loss: 0.282390, Val Loss: 0.335420, Val Acc: 0.848567, Val Prec: 0.851059, Val Rec: 0.848294, Val F1: 0.848783>\n",
      "Epoch 72/100: <Train Loss: 0.282269, Val Loss: 0.335006, Val Acc: 0.848636, Val Prec: 0.850947, Val Rec: 0.848065, Val F1: 0.848752>\n",
      "Epoch 73/100: <Train Loss: 0.278522, Val Loss: 0.340747, Val Acc: 0.847251, Val Prec: 0.850360, Val Rec: 0.846559, Val F1: 0.846409>\n",
      "Epoch 74/100: <Train Loss: 0.280869, Val Loss: 0.346839, Val Acc: 0.839565, Val Prec: 0.841490, Val Rec: 0.839505, Val F1: 0.839499>\n",
      "Epoch 75/100: <Train Loss: 0.281213, Val Loss: 0.338270, Val Acc: 0.850505, Val Prec: 0.852774, Val Rec: 0.850035, Val F1: 0.850693>\n",
      "Epoch 76/100: <Train Loss: 0.278840, Val Loss: 0.340966, Val Acc: 0.850782, Val Prec: 0.852768, Val Rec: 0.850423, Val F1: 0.851014>\n",
      "Epoch 77/100: <Train Loss: 0.278753, Val Loss: 0.339238, Val Acc: 0.846005, Val Prec: 0.848775, Val Rec: 0.845358, Val F1: 0.846070>\n",
      "Epoch 78/100: <Train Loss: 0.277795, Val Loss: 0.336189, Val Acc: 0.850229, Val Prec: 0.852402, Val Rec: 0.849745, Val F1: 0.850424>\n",
      "Epoch 79/100: <Train Loss: 0.277415, Val Loss: 0.340271, Val Acc: 0.849605, Val Prec: 0.851922, Val Rec: 0.849379, Val F1: 0.849692>\n",
      "Epoch 80/100: <Train Loss: 0.277055, Val Loss: 0.339886, Val Acc: 0.850990, Val Prec: 0.852498, Val Rec: 0.850592, Val F1: 0.851169>\n",
      "Epoch 81/100: <Train Loss: 0.276748, Val Loss: 0.341734, Val Acc: 0.849259, Val Prec: 0.851867, Val Rec: 0.848750, Val F1: 0.849471>\n",
      "Epoch 82/100: <Train Loss: 0.276995, Val Loss: 0.347529, Val Acc: 0.844620, Val Prec: 0.846284, Val Rec: 0.844010, Val F1: 0.844482>\n",
      "Epoch 83/100: <Train Loss: 0.274929, Val Loss: 0.343600, Val Acc: 0.849121, Val Prec: 0.851701, Val Rec: 0.848699, Val F1: 0.849291>\n",
      "Epoch 84/100: <Train Loss: 0.275608, Val Loss: 0.343853, Val Acc: 0.849121, Val Prec: 0.851543, Val Rec: 0.848722, Val F1: 0.849324>\n",
      "Epoch 85/100: <Train Loss: 0.275981, Val Loss: 0.343041, Val Acc: 0.848428, Val Prec: 0.851724, Val Rec: 0.848002, Val F1: 0.848621>\n",
      "Epoch 86/100: <Train Loss: 0.274376, Val Loss: 0.348442, Val Acc: 0.844481, Val Prec: 0.845722, Val Rec: 0.844179, Val F1: 0.844656>\n",
      "Epoch 87/100: <Train Loss: 0.273394, Val Loss: 0.345433, Val Acc: 0.842335, Val Prec: 0.850658, Val Rec: 0.842687, Val F1: 0.839932>\n",
      "Epoch 88/100: <Train Loss: 0.273329, Val Loss: 0.348863, Val Acc: 0.846905, Val Prec: 0.849720, Val Rec: 0.846330, Val F1: 0.847094>\n",
      "Epoch 89/100: <Train Loss: 0.273734, Val Loss: 0.352528, Val Acc: 0.845451, Val Prec: 0.847195, Val Rec: 0.844909, Val F1: 0.845464>\n",
      "Epoch 90/100: <Train Loss: 0.274455, Val Loss: 0.350663, Val Acc: 0.849328, Val Prec: 0.851290, Val Rec: 0.848891, Val F1: 0.849524>\n",
      "Epoch 91/100: <Train Loss: 0.271884, Val Loss: 0.362717, Val Acc: 0.845035, Val Prec: 0.846027, Val Rec: 0.844671, Val F1: 0.845142>\n",
      "Epoch 92/100: <Train Loss: 0.273790, Val Loss: 0.348475, Val Acc: 0.848567, Val Prec: 0.851040, Val Rec: 0.848008, Val F1: 0.848750>\n",
      "Epoch 93/100: <Train Loss: 0.272806, Val Loss: 0.353121, Val Acc: 0.843720, Val Prec: 0.845982, Val Rec: 0.843453, Val F1: 0.843745>\n",
      "Epoch 94/100: <Train Loss: 0.271889, Val Loss: 0.353448, Val Acc: 0.849190, Val Prec: 0.850664, Val Rec: 0.848789, Val F1: 0.849372>\n",
      "Epoch 95/100: <Train Loss: 0.272363, Val Loss: 0.356617, Val Acc: 0.845520, Val Prec: 0.846914, Val Rec: 0.845083, Val F1: 0.845586>\n",
      "Epoch 96/100: <Train Loss: 0.271846, Val Loss: 0.350873, Val Acc: 0.847043, Val Prec: 0.849517, Val Rec: 0.846432, Val F1: 0.847145>\n",
      "Epoch 97/100: <Train Loss: 0.272223, Val Loss: 0.349227, Val Acc: 0.847943, Val Prec: 0.849512, Val Rec: 0.847580, Val F1: 0.848110>\n",
      "Epoch 98/100: <Train Loss: 0.270065, Val Loss: 0.354707, Val Acc: 0.846143, Val Prec: 0.847926, Val Rec: 0.845906, Val F1: 0.846335>\n",
      "Epoch 99/100: <Train Loss: 0.270282, Val Loss: 0.355131, Val Acc: 0.847597, Val Prec: 0.848794, Val Rec: 0.847251, Val F1: 0.847765>\n",
      "Epoch 100/100: <Train Loss: 0.270866, Val Loss: 0.355126, Val Acc: 0.847736, Val Prec: 0.849882, Val Rec: 0.847255, Val F1: 0.847953>\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T21:09:07.898931Z",
     "start_time": "2024-12-01T21:09:06.419897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate on the test set\n",
    "loss, accuracy, precision, recall, f1 = evaluate(model, test_loader, criterion)\n",
    "print(f'Test Loss: {loss:.6f}'\n",
    "      f'\\nAccuracy: {accuracy:.6f}'\n",
    "      f'\\nPrecision: {precision:.6f}'\n",
    "      f'\\nRecall: {recall:.6f}'\n",
    "      f'\\nF1-score: {f1:.6f}')"
   ],
   "id": "eb08091fba7e6dc5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.366879\n",
      "Accuracy: 0.841169\n",
      "Precision: 0.843460\n",
      "Recall: 0.840088\n",
      "F1-score: 0.840861\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
